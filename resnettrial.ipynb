{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnettrial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kp713/Breast-Cancer-DDSM-Detection-Using-ResNet/blob/main/resnettrial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AU8uAIFblK2r"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torchvision\n",
        "from collections import OrderedDict\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "from torch.optim import lr_scheduler\n",
        "import copy\n",
        "import json\n",
        "import os\n",
        "from os.path import exists\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import sklearn.metrics\n",
        "#import sklearn.metrics.roc_auc_score as roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, f1_score,accuracy_score\n",
        "#import sklearn.metrics.PrecisionRecallDisplay as precisionrecalldisplay\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULZJasohr7nh"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, valloss, model):\n",
        "\n",
        "        score = -valloss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(valloss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(valloss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, valloss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {valloss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = valloss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1BKDQkMlY0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "outputId": "9ab02056-f6fc-439f-bc29-d4568159ba32"
      },
      "source": [
        "#%%\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TIMEOUT",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTIMEOUT\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-83af538e4ac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#%%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0moauth_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mproblem_and_stopped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mdrive_exited\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     ])\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(self, pattern, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mcompiled_pattern_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_pattern_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         return self.expect_list(compiled_pattern_list,\n\u001b[0;32m--> 344\u001b[0;31m                 timeout, searchwindowsize, async_)\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     def expect_list(self, pattern_list, timeout=-1, searchwindowsize=-1,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpect_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     def expect_exact(self, pattern_list, timeout=-1, searchwindowsize=-1,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTIMEOUT\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mtimeout\u001b[0;34m(self, err)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTIMEOUT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m    \u001b[0;31m# in Python 3.x we can use \"raise exc from None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merrored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTIMEOUT\u001b[0m: <pexpect.popen_spawn.PopenSpawn object at 0x7f689898ad30>\nsearcher: searcher_re:\n    0: re.compile('google.colab.drive MOUNTED')\n    1: re.compile('root@ee82ecde4617-18901a2788ac42a0ab0b7ddef165492c: ')\n    2: re.compile('(Go to this URL in a browser: https://.*)$')\n    3: re.compile('Drive File Stream encountered a problem and has stopped')\n    4: re.compile('drive EXITED')\n<pexpect.popen_spawn.PopenSpawn object at 0x7f689898ad30>\nsearcher: searcher_re:\n    0: re.compile('google.colab.drive MOUNTED')\n    1: re.compile('root@ee82ecde4617-18901a2788ac42a0ab0b7ddef165492c: ')\n    2: re.compile('(Go to this URL in a browser: https://.*)$')\n    3: re.compile('Drive File Stream encountered a problem and has stopped')\n    4: re.compile('drive EXITED')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP5b_1Tigzhe"
      },
      "source": [
        "#!unzip -uq \"/content/drive/My Drive/CancerData40mag\" -d \"/content/drive/My Drive/40Mag\"\n",
        "#This code unzips the folder in google drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_XQgFvCmOhu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "392697a8-ef83-4e5b-867f-6beef630787b"
      },
      "source": [
        "PATH_OF_DATA= '/content/drive/\"My Drive\"/40mag'\n",
        "!ls {PATH_OF_DATA}\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/My Drive/40mag'\n",
        "os.listdir('/content/drive/My Drive/40mag')\n",
        "\n",
        "#In this block of code, we initialize the path of the data and set the data directory which will be used later.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train  val\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['val', 'test', 'train']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mUYXVqmfFWq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "806f567a-9c44-4865-c1c1-067db4243b6b"
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "nThreads = 4\n",
        "batch_size = 32\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "#This code block checks the availability of a GPU for training the model.\n",
        "#Here we're also setting the number of workers and the batch size for training on the gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcV6j7E_83-W"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQv4yIs9mvBJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "d3c78f2f-5e5d-46d8-acdb-8097391ace1e"
      },
      "source": [
        "\n",
        "#plt.imshow(image_datasets[\"train\"][0][1].permute(1,2,0))\n",
        "#plt.show\n",
        "plt.imshow(image_datasets[\"train\"][1][0].permute(1,2,0) )\n",
        "\n",
        "print(len(image_datasets[\"test\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6b0399ed4b43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#plt.imshow(image_datasets[\"train\"][0][1].permute(1,2,0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#plt.show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image_datasets' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsqylCSLm7LH"
      },
      "source": [
        "#train_transforms = transforms.Compose([\n",
        " #       transforms.RandomRotation(30),\n",
        "  #      transforms.RandomResizedCrop(224),\n",
        "   #     #transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
        "    #    transforms.RandomHorizontalFlip(),\n",
        "     #   transforms.ToTensor(),\n",
        "      #  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    #])\n",
        "#test_transforms = transforms.Compose([\n",
        " #       transforms.Resize(256),\n",
        " #       transforms.CenterCrop(224),\n",
        " #       transforms.ToTensor(),\n",
        " #       transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "  #  ])\n",
        "train_transforms =transforms.Compose([\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.RandomResizedCrop(32),\n",
        "        #transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transforms =transforms.Compose([\n",
        "        transforms.Resize(32),\n",
        "        #transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
        "        #transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "val_transforms =transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        #transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
        "        #transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "#making the training, test and val sets and their dataloaders\n",
        "train_set = datasets.ImageFolder(root=\"/content/drive/My Drive/40mag/train\",transform=train_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=4)\n",
        "\n",
        "\n",
        "\n",
        "test_set = datasets.ImageFolder(root=\"/content/drive/My Drive/40mag/test\",transform=test_transforms)\n",
        "\n",
        "test_loader = DataLoader(test_set,batch_size=batch_size,shuffle=False,num_workers=4)\n",
        "\n",
        "val_set = datasets.ImageFolder(root=\"/content/drive/My Drive/40mag/val\",transform=val_transforms)\n",
        "\n",
        "val_loader = DataLoader(val_set,batch_size=batch_size,shuffle=True,num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrtkVkVtt3vs"
      },
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n",
        "           'wide_resnet50_2', 'wide_resnet101_2']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
        "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
        "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
        "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
        "\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        \n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', BasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
        "                   **kwargs)\n",
        "    \n",
        "def resnet152(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-152 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet152', Bottleneck, [3, 8, 36, 3], pretrained, progress,\n",
        "                   **kwargs)\n",
        "def resnet34(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-34 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet34', BasicBlock, [3, 4, 6, 3], pretrained, progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "def resnet50(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-50 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "def resnet101(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-101 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet101', Bottleneck, [3, 4, 23, 3], pretrained, progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y11F7Ujwpo_g"
      },
      "source": [
        "class Unit(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels):\n",
        "        super(Unit,self).__init__()\n",
        "        \n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels,kernel_size=3,out_channels=out_channels,stride=1,padding=1)\n",
        "        self.bn = nn.BatchNorm2d(num_features=out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self,input):\n",
        "        output = self.conv(input)\n",
        "        output = self.bn(output)\n",
        "        output = self.relu(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self,num_classes=2):\n",
        "        super(SimpleNet,self).__init__()\n",
        "\n",
        "        #Create 14 layers of the unit with max pooling in between\n",
        "        self.unit1 = Unit(in_channels=3,out_channels=32)\n",
        "        self.unit2 = Unit(in_channels=32, out_channels=32)\n",
        "        self.unit3 = Unit(in_channels=32, out_channels=32)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit4 = Unit(in_channels=32, out_channels=64)\n",
        "        self.unit5 = Unit(in_channels=64, out_channels=64)\n",
        "        self.unit6 = Unit(in_channels=64, out_channels=64)\n",
        "        self.unit7 = Unit(in_channels=64, out_channels=64)\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit8 = Unit(in_channels=64, out_channels=128)\n",
        "        self.unit9 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit10 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit11 = Unit(in_channels=128, out_channels=128)\n",
        "\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        self.unit12 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit13 = Unit(in_channels=128, out_channels=128)\n",
        "        self.unit14 = Unit(in_channels=128, out_channels=128)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=4)\n",
        "        \n",
        "        #Add all the units into the Sequential layer in exact order\n",
        "        self.net = nn.Sequential(self.unit1, self.unit2, self.unit3, self.pool1, self.unit4, self.unit5, self.unit6\n",
        "                                 ,self.unit7, self.pool2, self.unit8, self.unit9, self.unit10, self.unit11, self.pool3,\n",
        "                                 self.unit12, self.unit13, self.unit14, self.avgpool)\n",
        "\n",
        "        self.fc = nn.Linear(in_features=128,out_features=128)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.net(input)\n",
        "        output = output.view(-1,128)\n",
        "        output = self.fc(output)\n",
        "        return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlMXy6fhn-5Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "1fcbcada-74fb-4cf9-f46f-424b4bdec35e"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "#here we load the model we wrote the code for previously\n",
        "model = resnet152(pretrained=false)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False  #this is for whether we want to freeze our parameters or not\n",
        "\n",
        "#this prints the model architecture\n",
        "    print(model)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "#here we describe the structure of our classifier\n",
        "\n",
        "classifier = nn.Sequential(OrderedDict([\n",
        "                         ('fc1', nn.Linear(128, 64)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('dropout1', nn.Dropout(p=0.1)),\n",
        "                          ('fc2', nn.Linear(64, 2)),\n",
        "                           # ('relu', nn.ReLU()),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))\n",
        "\n",
        "#loading our classifier\n",
        "model.fc = classifier\n",
        "num_classes =2\n",
        "valloss = []\n",
        "trainloss =[]\n",
        "valacc= []\n",
        "trainacc = []\n",
        "patience = 30 #threshold for early stopping\n",
        "\n",
        "early_stopping = EarlyStopping(patience=patience, verbose=True) # if 30 times conescutively the loss does not decrease, the model stops training\n",
        "\n",
        "\n",
        "#Function to train the model\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs,patience):\n",
        "    since = time.time()\n",
        "  \n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        \n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "                model.train()  #training mode\n",
        "            else:\n",
        "                model.eval()   # eval mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # loading data with dataloaders\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                # initialize the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward prop\n",
        "                \n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward prop\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # calculating accuracy, loss\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "            if phase == \"train\" :\n",
        "                trainloss.append (epoch_loss) #storing each loss and accuracy of epoch in a list\n",
        "                trainacc.append(epoch_acc)\n",
        "            else :\n",
        "                valloss.append (epoch_loss)\n",
        "                valacc.append(epoch_acc)\n",
        "        \n",
        "    \n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc)) #printing each loss and accuracy for both phases\n",
        "\n",
        "            # this stores the model weights for the best model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                en = epoch\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "           \n",
        "        early_stopping(valloss[epoch-1], model) #early stopping\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "              print(\"Early stopping\")\n",
        "              break\n",
        "        model.load_state_dict(torch.load('checkpoint.pt')) #stores the checkpoint if early stopping is implemented\n",
        "\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid accuracy: {:4f}'.format(best_acc))\n",
        "    #print (\"Best Model weights : \",best_model_wts)  #Optional code to print best model weights\n",
        "    print (trainloss)\n",
        "    print (valloss)\n",
        "\n",
        "    #as accuracy gets stored as a tensor, we need to convert it to numpy for plotting a graph\n",
        "    def tensortonumpy (acc) :\n",
        "          x = acc\n",
        "          nparray = []\n",
        "   \n",
        "          for i in range (en):\n",
        "               a = x[i]\n",
        "               a = a.cpu()\n",
        "               b = a.numpy()\n",
        "               c = float(b)\n",
        "               nparray.append(c)\n",
        "          return nparray\n",
        "    val_acc = tensortonumpy(valacc)\n",
        "    train_acc =tensortonumpy(trainacc)\n",
        "    print(train_acc)\n",
        "    print(val_acc)\n",
        "\n",
        "    model.load_state_dict(best_model_wts) #loads weights of the best model\n",
        "\n",
        "    #in this section we plot the graphs\n",
        "    def mean(li): return sum(li)/len(li)\n",
        "    plt.figure(figsize=(14, 4))\n",
        "    plt.xlabel('training batch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.plot([mean(trainloss[i:i+num_epochs]) for i in range(len(trainloss))])\n",
        "\n",
        "    def mean(li): return sum(li)/len(li)\n",
        "    plt.figure(figsize=(14, 4))\n",
        "    plt.xlabel('validation batch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.plot([mean(valloss[i:i+num_epochs]) for i in range(len(valloss))])\n",
        "\n",
        "    def mean(li): return sum(li)/len(li)\n",
        "    plt.figure(figsize=(14, 4))\n",
        "    plt.xlabel('training batch')\n",
        "    plt.ylabel('epoch')\n",
        "    plt.plot(train_acc)\n",
        "\n",
        "    def mean(li): return sum(li)/len(li)\n",
        "    plt.figure(figsize=(14, 4))\n",
        "    plt.xlabel('validation batch')\n",
        "    plt.ylabel('epoch')\n",
        "    plt.plot(val_acc)\n",
        "    \n",
        "    return model\n",
        "    return trainloss,valloss\n",
        "    return train_acc,val_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-08466181fdcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#here we load the model we wrote the code for previously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet152\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'resnet152' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwMkZkZCxIXZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sALiZfluxH78"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykLWdIjLoXND",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "92543f3c-789c-4cfc-850f-59937a938482"
      },
      "source": [
        "num_epochs =3\n",
        "if use_gpu:\n",
        "    print (\"Using GPU: \"+ str(use_gpu))\n",
        "    model = model.cuda()\n",
        "\n",
        "# NLLLoss because our output is LogSoftmax\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Adam optimizer with a learning rate\n",
        "#optimizer = optim.Adam(model.fc.parameters(), lr=0.0001,weight_decay = 0.001)\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr = .0001, momentum=0.09, weight_decay = 0.01)\n",
        "# Decay LR by a factor--  every -- epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
        "\n",
        "\n",
        "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs,patience)\n",
        "torch.save(model_ft.state_dict(), \"simplenet.pth\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU: True\n",
            "Epoch 1/3\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4ac15ac16032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"simplenet.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-033adb627742>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs, patience)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# loading data with dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataLoaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DataLoaders' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqF7fjm7-A5N"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EfYb2CxIYMP"
      },
      "source": [
        "# Do validation on the test set\n",
        "def test(model, dataloaders, device):\n",
        "  model.eval()\n",
        "  actuals = []\n",
        "  probabilities = []\n",
        "  predictions = []\n",
        "  accuracy = 0\n",
        "  \n",
        "  model.to(device)\n",
        "    \n",
        "  for images, labels in dataloaders['test']:\n",
        "    images = Variable(images)\n",
        "    labels = Variable(labels)\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "      \n",
        "    output = model.forward(images)\n",
        "    ps = torch.exp(output)\n",
        "    equality = (labels.data == ps.max(1)[1])\n",
        "    accuracy += equality.type_as(torch.FloatTensor()).mean()\n",
        "    ##\n",
        "   \n",
        "\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            out    = output.cpu()\n",
        "            prediction = out.argmax(dim=1, keepdim=True)\n",
        "            actuals.extend(target.view_as(prediction) == 1)\n",
        "            probabilities.extend(np.exp((out[:, 1])))\n",
        "            \n",
        "    return [i.item() for i in actuals], [i.item() for i in probabilities]\n",
        "      \n",
        "    print(\"Testing Accuracy: {:.3f}\".format(accuracy/len(dataloaders['test'])))\n",
        "\n",
        "actuals, class_probabilities = test(model, dataloaders,device)\n",
        "\n",
        "fpr, tpr, _ = sklearn.metrics.roc_curve(actuals, class_probabilities)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC for digit=1 class Malignant')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "def test_label_predictions(model, device, test_loader):\n",
        "    model.eval()\n",
        "    actuals = []\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            prediction = output.argmax(dim=1, keepdim=True)\n",
        "            actuals.extend(target.view_as(prediction))\n",
        "            predictions.extend(prediction)\n",
        "    return [i.item() for i in actuals], [i.item() for i in predictions]\n",
        "\n",
        "actuals, predictions = test_label_predictions(model, device, test_loader)\n",
        "print('Confusion matrix:')\n",
        "print(confusion_matrix(actuals, predictions))\n",
        "print('F1 score: %f' % f1_score(actuals, predictions, average='micro'))\n",
        "print('Accuracy score: %f' % accuracy_score(actuals, predictions))\n",
        "\n",
        "#test(model, dataloaders, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FKY9lZboM9X"
      },
      "source": [
        "model.class_to_idx = dataloaders['train'].dataset.class_to_idx\n",
        "model.epochs = num_epochs\n",
        "checkpoint = {'input_size': [3, 224, 224],\n",
        "                 'batch_size': dataloaders['train'].batch_size,\n",
        "                  'output_size': 2,\n",
        "                  'state_dict': model.state_dict(),\n",
        "                  'data_transforms': data_transforms,\n",
        "                  'optimizer_dict':optimizer.state_dict(),\n",
        "                  'class_to_idx': model.class_to_idx,\n",
        "                  'epoch': model.epochs}\n",
        "torch.save(checkpoint, 'checkpoint.pth')\n",
        "\n",
        "\n",
        "#Load the trained model from here:\n",
        "!gdown https://drive.google.com/drive/u/1/my-drive\n",
        "#https://drive.google.com/open?id=16RqsH1oCROSJiCR0f2gWCs4Xaz3JRTw9\n",
        "\n",
        "# Write a function that loads a checkpoint and rebuilds the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQNynhnJJUSt"
      },
      "source": [
        "\n",
        "\n",
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = resnet50()\n",
        "    \n",
        "    # Our input_size matches the in_features of pretrained model\n",
        "    input_size = 2048\n",
        "    output_size = 2\n",
        "    \n",
        "    classifier = nn.Sequential(OrderedDict([\n",
        "                          ('fc1', nn.Linear(2048, 512)),\n",
        "                          ('relu', nn.ReLU()),\n",
        "                          ('dropout1', nn.Dropout(p=0.1)),\n",
        "                          ('fc2', nn.Linear(512, 2)),\n",
        "                          ('output', nn.LogSoftmax(dim=1))\n",
        "                          ]))\n",
        "\n",
        "# Replacing the pretrained model classifier with our classifier\n",
        "    model.fc = classifier\n",
        "    \n",
        "    state_dict = torch.load('checkpoint.pth')\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    \n",
        "    return model, checkpoint['class_to_idx']\n",
        "\n",
        "# Get index to class mapping\n",
        "loaded_model, class_to_idx = load_checkpoint('checkpoint.pth')\n",
        "idx_to_class = { v : k for k,v in class_to_idx.items()}\n",
        "\n",
        "\"\"\"# Inference for classification\n",
        "Now you'll write a function to use a trained network for inference. That is, you'll pass an image into the network and predict the class. Write a function called `predict` that takes an image and a model, then returns the top $K$ most likely classes along with the probabilities. It should look like\n",
        "\"\"\"\n",
        "\n",
        "def process_image(image):\n",
        "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
        "        returns an Numpy array\n",
        "    '''\n",
        "    \n",
        "    # Process a PIL image for use in a PyTorch model\n",
        "\n",
        "    size = 256, 256\n",
        "    image.thumbnail(size, Image.ANTIALIAS)\n",
        "    image = image.crop((128 - 112, 128 - 112, 128 + 112, 128 + 112))\n",
        "    npImage = np.array(image)\n",
        "    npImage = npImage/255.\n",
        "        \n",
        "    imgA = npImage[:,:,0]\n",
        "    imgB = npImage[:,:,1]\n",
        "    imgC = npImage[:,:,2]\n",
        "    \n",
        "    imgA = (imgA - 0.485)/(0.229) \n",
        "    imgB = (imgB - 0.456)/(0.224)\n",
        "    imgC = (imgC - 0.406)/(0.225)\n",
        "        \n",
        "    npImage[:,:,0] = imgA\n",
        "    npImage[:,:,1] = imgB\n",
        "    npImage[:,:,2] = imgC\n",
        "    \n",
        "    npImage = np.transpose(npImage, (2,0,1))\n",
        "    \n",
        "    return npImage\n",
        "\n",
        "def imshow(image, ax=None, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    \n",
        "    # PyTorch tensors assume the color channel is the first dimension\n",
        "    # but matplotlib assumes is the third dimension\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "    \n",
        "    # Undo preprocessing\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = std * image + mean\n",
        "    \n",
        "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
        "    image = np.clip(image, 0, 1)\n",
        "    \n",
        "    ax.imshow(image)\n",
        "    \n",
        "    return ax\n",
        "\n",
        "\"\"\"# Class Prediction\n",
        "Once you can get images in the correct format, it's time to write a function for making predictions with your model. A common practice is to predict the top 5 or so (usually called top-$K$) most probable classes. You'll want to calculate the class probabilities then find the $K$ largest values.\n",
        "To get the top $K$ largest values in a tensor use [`x.topk(k)`](http://pytorch.org/docs/master/torch.html#torch.topk). This method returns both the highest `k` probabilities and the indices of those probabilities corresponding to the classes. You need to convert from these indices to the actual class labels using `class_to_idx` which hopefully you added to the model or from an `ImageFolder` you used to load the data ([see here](#Save-the-checkpoint)). Make sure to invert the dictionary so you get a mapping from index to class as well.\n",
        "Again, this method should take a path to an image and a model checkpoint, then return the probabilities and classes.\n",
        "```python\n",
        "probs, classes = predict(image_path, model)\n",
        "print(probs)\n",
        "print(classes)\n",
        "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
        "> ['70', '3', '45', '62', '55']\n",
        "\"\"\"\n",
        "\n",
        "def predict(image_path, model, topk=2):\n",
        "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
        "    '''\n",
        "    \n",
        "    # Implement the code to predict the class from an image file\n",
        "    \n",
        "    image = torch.FloatTensor([process_image(Image.open(image_path))])\n",
        "    model.eval()\n",
        "    output = model.forward(Variable(image))\n",
        "    pobabilities = torch.exp(output).data.numpy()[0]\n",
        "    \n",
        "\n",
        "    top_idx = np.argsort(pobabilities)[-topk:][::-1] \n",
        "    top_class = [idx_to_class[x] for x in top_idx]\n",
        "    top_probability = pobabilities[top_idx]\n",
        "\n",
        "    return top_probability, top_class\n",
        "\n",
        "print (predict('/content/drive/My Drive/minsplitdata/minsplitdata/test/malignant/SOB_M_DC-14-5695-40-017.png', loaded_model))\n",
        "\n",
        "\"\"\"# Sanity Checking\n",
        "Now that you can use a trained model for predictions, check to make sure it makes sense. Even if the validation accuracy is high, it's always good to check that there aren't obvious bugs. Use `matplotlib` to plot the probabilities for the top 5 classes as a bar graph, along with the input image. It should look like this:\n",
        "\"\"\"\n",
        "\n",
        "# Display an image along with the top 2 classes\n",
        "def view_classify(img, probabilities, classes, mapper):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    img_filename = img.split('/')[-2]\n",
        "    img = Image.open(img)\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,10), ncols=1, nrows=2)\n",
        "    cancer_type = mapper[img_filename]\n",
        "    \n",
        "    ax1.set_title(cancer_type)\n",
        "    ax1.imshow(img)\n",
        "    ax1.axis('off')\n",
        "    \n",
        "    y_pos = np.arange(len(probabilities))\n",
        "    ax2.barh(y_pos, probabilities)\n",
        "    ax2.set_yticks(y_pos)\n",
        "    ax2.set_yticklabels([mapper[x] for x in classes])\n",
        "    ax2.invert_yaxis()\n",
        "\n",
        "cat_to_name = {\"benign\":\"benign\",\"malignant\":\"malignant\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-AA6r8cOWk-"
      },
      "source": [
        "img = '/content/drive/My Drive/minsplitdata/minsplitdata/test/malignant/SOB_M_DC-14-5695-40-017.png'\n",
        "p, c = predict(img, loaded_model)\n",
        "view_classify(img, p, c,cat_to_name)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}